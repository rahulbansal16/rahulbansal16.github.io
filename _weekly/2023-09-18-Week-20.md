---
layout: post
title: Week  Goals
visible: 0
summary: "Week 19 Task Planning, Retros and Learnings"
---

Weeks Goal
1. Add animation to the editor.
2. Add sound track library.
3. Wire up the midjourney for the images.
4. Make audiopen product.
5. Aim for the 4 i.e 50X4 minutes of focused session.
6. Build the nextjs project that might be convertstring alternative.
7. Might generate the content for linkedimn

Monday
1. Added the audio search functionality.

Tuesday - 4 Pomodoros
1. Add more animations to the background image.
2. modify the prompt to accept those effects.
3. Fix the freesound api

Wednesday - 4 Pomodoros
1. Figure out image generation using the stability

Thursday 5 pomo
1. Get the stable diffusion model working
2. Wire up the product and launch it.

Friday - 4 Pomodoros
1. Moved to API model
2. Wrote a Post on Linkedin
3. Improved the biodataformats

Saturday - 
1. Verify the image generation is working.
2. Focus on improving the end to end flow.
3. Get Your Product Live.

Get the gtag working with the biodataformats.com Not very urgent as of now.
https://analytics.google.com/analytics/web/#/a283493484p404723935/admin/account/create

```js
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3GLBERPT45"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3GLBERPT45');
</script>
```

Retro
1. Able to bounce back to 4 Pomodoros this week.
2. Made some good progress on biodataformats and blinkcuts.

Learning
1. Execute things end to end.

Thursday
1. Research about the model for generating sounds.
    a. Search the models
    b. Try Hugging Face or the other way of trying them.
    c. There are Google MusicLM, and few other models.
    d. No one provide API access.
    e. Facebook has published the model and it can be used to get the API.
    f. What's the fastest way to get an API out of the collab Notebook?
        i. Should I convert it to an python flask API?
        ii. Are there any tools available to convert Google collab to API?
        iii. Does Hugging Face provides API access to the models?
2. Check what can be done with the prompts
    a. Add a input box for story.
    b. This should give the scene output.
    c. User can directly Edit the Scenes by clicking on them.

3. Figure out a way to built nextjs app to generate content.



What I want to achieve.
1. Tell us what are you building.
2. What have you learned, I started with building tool for people to burn subtitles in the video.
3. I realized that building faceless video is pain, so I pivoted to building videos and building a tool that does that.
4. What have you learned,  Learned to put myself out, I am shy guy and it's hard for me to put my work out, but through buildspace
learned two important things, Put your work out, Whenever you see something interesting, Ask yourself questions like Why is this intersting.
5. How do you measure success. I am measuring success by how much video I can automate using the script.
6. How you have been iterating, I started with building a subtitles editor, Than I pivoted to software that sends a personalised video by saying out the name of the person
7. What do you plan to do next, I want to focus on building a tool that can generate the AI videos just from script.
8. Did you pivot4? Yes, I pivoted from a tool to just burn subtitles to a tool that can generate AI videos.

Learnings 
1. Execute things end to end.
2. It's easy to build anything just get started on the first step. 
